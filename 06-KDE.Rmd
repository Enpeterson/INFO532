# Introduction to Kernel Density Estimation

**Motivations for statistical analyses**

-   To explore and visualize data.
-   To create and calibrate models of the process generating the data.
-   To test hypotheses related to the processes generating the data.
-   The kinds of analysis related to spatial data are distinctive, i.e.
    -   detection and location of clusters or events.
    -   spatial distributions of events
    -   spatial autocorrelation
    -   Are neighbors correlated?


## Point Patterns

-   Collections of geographical points (i.e. breaches) assumed to have been generated by a random process.

-   Consists of a set of observed $(x,y)$ coordinates.

-   We want to assess if locations of points are related (i.e. if the points refer to locations of cases of a contagious disease, then it is likely they occur near each other and therefore not independent.)

-   Can we say something about the population based on a finite set of data?

## Surfaces showing where events are more likely to happen

-   A probability density function (PDF) is a function that gives the probability (likelihood) of an event occurring at each location in your space.

-   Gives a surface across space showing where events are more likely to happen.

-   Displayed as a raster image: Fine grid of colors where colors correspond to density or intensity of events.

    -   Density: The probability of an event occurring at location $s$.
    -   Intensity: The expected number of events occurring at location $s$.
    -   Note: Intensity $=$ number of events across all locations $\times$ Density.

## Kernel Density Estimation (KDE)

-   Let $f(x)$ denote the intensity function (expected number of cases per unit distance at location $s$).

-   We estimate $f(x)$ via kernel estimation. What does that mean?

    -   Place a small "kernel" at each observed data point.
        -   Spreads each observation around  usually with something that looks like a normal distribution.
    -   Sum kernel values to give intensity estimate at each location $s$.
    -   KDE averages a series of small "bumps" (2 dim probability distributions) centered on each observed point.


-   Figure: initial points (left), bump centered on each point (middle), average of bumps giving estimate of probability density (right)

## 

In algebraic terms, the approximation $f(\mathbf{x})$ for a given location $\mathbf{x} = (x,y)$ is given by: $$\hat{f}(x) = \hat{f}(x,y) = \frac{1}{n \cdot b_x \cdot b_y} \sum_i k\left(\frac{x-x_i}{b_x}, \frac{y-y_i}{b_y}\right)$$

-   Kernel Function: $k\left(\frac{x-x_i}{b_x}, \frac{y-y_i}{b_y}\right)$ creates the bumps. Must be a non-negative function.
-   $i=$ location index.
- The entire equation describes the "bump averaging process".

 $b=$ Bandwidth
        -   Related to the variance of the kernel (how wide it is?)
        -   How much do we spread each observation?
        -   Controls the smoothness of the density estimate (Larger $b$ gives smoother surface)
-   $b_y, b_x$ refer to bandwidths that control how much you want to smooth the probability density surface. Lower values of $b's$ give spiky distributions and high values flatten the distribution.


-   Figure: too small $b's$ (left). appropriate $b's$ (middle), too high (right)


## How to choose bandwidth

-   One obvious question is how to choose the bandwidth given your dataset $\mathbf{x}_i$.
-   Here is general rule of thumb: $$b_x = s_x \left(\frac{2}{3n}\right) ^{1/6}$$ $$b_y = s_y \left(\frac{2}{3n}\right) ^{1/6}$$

where $s_x, s_y$ is the standard deviation of the $x_i$ and $y_i$. 



## Let's look again at the Breach data...
(First you need to install a package from Github using code below)
```{r, eval = F}
 # install.packages("remotes")
 remotes::install_github("mtennekes/oldtmaptools")

```

Steps to estimate the KDE:
1. Take each blue point.
2. Create a small distribution (bump) around each point, usually a normal distn.
3. Average across the bumps to calculate KDE.
```{r, message = F, error =F, eval = F}
library(tidyverse)
library(GISTools)
library(sp)
library(rgeos)
library(tmap)
library(oldtmaptools)

# Get the data
data(newhaven)
# look at it
# select 'view' mode
tmap_mode('view')
tmap_options(check.and.fix = TRUE)
# Create the map of blocks and incidents
tm_shape(blocks) + 
  tm_borders() + 
  tm_shape(breach) +
  tm_dots(col='navyblue')
```

## How to calculate KDEs
-   The function to compute KDE is *map_smooth* from the *oldtmaptools* packages.
-   This estimates the value of the density of over a grid of points, and returns a list with the following elements:
    -   a raster object: a raster grid of values for the KDEs
    -   a contour object: a set of contour lines
    -   a polygon object: a list of polygons

```{r, message = F, error =F, eval = F}
# Function to choose bandwidth according Bowman and Azzalini / Scott's rule
# for use with <smooth_map> in <tmaptools>

choose_bw <- function(spdf) {
  X <- coordinates(spdf)
  sigma <- c(sd(X[,1]),sd(X[,2]))  * (2 / (3 * nrow(X))) ^ (1/6)
  return(sigma/1000)
}
#Calculate KDE
  # bandwith argument: vector of length 2
  # cover argument: geometric object containing the boundaries of locations to estimate KDE.
  #smooth_map expects bandwidth in kms, so we divide by 1000 in our bw function.

breach_dens <- smooth_map(breach,cover=blocks, bandwidth = choose_bw(breach))
```

Let's look at what we have created

```{r, message = F, error =F, eval = F}

breach_dens$raster
breach_dens$iso
breach_dens$polygons
```

Plot the KDE outcomes in raster form.
```{r, message = F, error =F, eval = F}
#Plot the KDE
library(sf)

breach_sf <- st_as_sf(breach)
# Number plotted is expected number of cases per unit area
tm_shape(breach_dens$raster) + tm_raster() + tm_shape(breach_sf) + tm_dots(col="blue")

```
Note the count caption indicates probability densities have been rescaled to represent intensities- by multiplying the KDE by number of cases.

Plot the KDE outcomes using contour lines.

```{r,message = F, error =F, eval = F}
tmap_mode('view')
tmap_options(check.and.fix = TRUE)
# Create the map of blocks and incidents
tm_shape(blocks) + 
  tm_borders(alpha = 0.5) + 
  tm_shape(breach_dens$iso) +
  tm_lines(col="darkred", lwd = 2)
```



Try plotting the KDE outcomes using polygons

```{r,message = F, error =F, eval = F}
#Add your code here
tmap_mode('view')
tmap_options(check.and.fix = TRUE)
# Create the map of blocks and incidents
tm_shape(blocks) + 
  tm_borders(alpha = 0.5) + 
  tm_shape(breach_dens$polygons) +
  tm_fill(col="level")
```

## Using KDE for comparisons

* We can use KDE to compare spatial distributions across groups.
* In *newhaven data* we have data relating to (1) break-ins using forced entry, and (2) break-ins that do not. 
* We may be interested in comparing the spatial distribution of the two groups across the area.
* Important: To compare spatial distributions, we need to specify a set of levels for intensity contours to be equal. 

### Operations for comparing KDE

1. Specify set of level for intensity contours to allow comparisons.
2. Compute KDE.
3. Draw each of the two maps
4. Use *tmap\_arrange()* to draw multiple maps.

```{r,message = F, error =F, eval = F}
# set contour levels
contours <- seq(0, 1.4, by = 0.2)

#calculate KDEs for both groups
brn_dens <- smooth_map(burgres.n, cover = blocks, breaks = contours, style = "fixed", bandwidth = choose_bw(burgres.n))

brf_dens <- smooth_map(burgres.f, cover = blocks, breaks = contours, style = "fixed", bandwidth = choose_bw(burgres.f))

#Create the maps and store them in variables
dn <- tm_shape(blocks) + tm_borders() + tm_shape(brn_dens$polygons) + tm_fill(col = "level", alpha = 0.8, title = "non-forced break-ins")
df <- tm_shape(blocks) + tm_borders() + tm_shape(brf_dens$polygons) + tm_fill(col = "level", alpha = 0.8, title = "forced break-ins") 

tmap_arrange(dn, df)
```


